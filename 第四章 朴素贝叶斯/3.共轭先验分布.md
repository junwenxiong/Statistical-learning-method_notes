# 3.共轭先验分布

## 背景
### 贝叶斯估计

$$先验分布+数据的知识=后验分布\ \ \ \ \ (*)$$


### 共轭先验分布的提出
1. 当没有任何观察数据时，随机变量$\theta$服从概率分布$P(\theta)$

2. 当观测到新的数据$X$时，有如下问题：

    1. 可否根据新观测到的数据$X$，更新参数$\theta$
    
    2. 根据新观测到的数据可以在多大程度上改变参数$\theta: \theta \leftarrow  \theta +\Delta \theta$
    
    3. 当重新估计$\theta$的时候，如何给出其新的概率分布$p(\theta|X)$

根据贝叶斯法则：

$$\large{p(\theta|x)=\frac{P(x|\theta) \cdot P(\theta)}{P(x)} \propto P(x|\theta) \cdot P(\theta)}$$

其中$P(x|\theta)$表示似然函数，可以直接求得。$P(\theta)$表示$\theta$的先验概率分布。若可以选择一个合适的先验分布$p(\theta)$，能使得**后验概率分布$P(\theta|x)$与先验概率分布$p(\theta)$有相同的形式**，则能够简化后验概率部分的求解。

## 定义
### Beta-Binomial 共轭

类比于公式$(*)$，Beta-Binomial共轭结构可以用下面这个公式说明：

$$Beta(p|\alpha,\beta) + BinomCount(m_{1},m_{2}) = Beta(p|\alpha+m_{1},\beta+m_{2})$$

这里共轭的意思就是，数据符合二项分布的时候，若参数的先验分布为Beta分布，则参数的后验分布仍然为Beta分布。

证明如下：

$$\large{\begin{equation}
\begin{split}
P(p|m_{1},m_{2}) &= \frac{P(p)\cdot P(m_{1},m_{2}|p)}{P(m_{1},m_{2})} \\
& = \frac{Beta(p|\alpha,\beta)\cdot Binomial(m_{1},m_{2}|p)}{\int Beta(p|\alpha,\beta)\cdot Binomial(m_{1},m_{2}|p)\ dp} \\
& = \frac{\frac{1}{B(\alpha,\beta)}p^{\alpha-1}(1-p)^{\beta-1}\cdot C_{m}^{m_{1}}p^{m_{1}}(1-p)^{m_{2}}}{\int \frac{1}{B(\alpha,\beta)}p^{\alpha-1}(1-p)^{\beta-1}\cdot C_{m}^{m_{1}}t^{m_{1}}(1-p)^{m_{2}}\ dp} \\
& = \frac{p^{\alpha+m_{1}-1}(1-p)^{\beta+m_{2}-1}}{\int p^{\alpha+m_{1}-1}(1-p)^{\beta+m_{2}-1} \ dp}
\end{split}
\end{equation}}$$

而上式中的**分母在积分后就与$p$无关**了，所以只有分子含有$p$，而且符合$Beta(p|\alpha+m_{1},\beta+m_{2})$，所以Beta服从共轭分布

### Dirichlet-Multinomial 共轭
若将Beta分布扩展到$N$维Dirichlet分布，同时将Binomial分布扩展到$N$维Multinomial分布，就得到了Dirichlet-Multinomial共轭结构

$$\large{Dir(\vec p|\vec \alpha) + MultiCount(\vec m) = Dir(\vec p|\vec \alpha + \vec m)}$$

此处共轭的意思是，数据符合multinomial分布，若参数的先验分布为Dirichlet分布，则参数的后验分布仍为Dirichlet分布。


**引用**

    https://blog.csdn.net/chenshulong/article/details/79034710#comments
    模式识别与机器学习（PRML）